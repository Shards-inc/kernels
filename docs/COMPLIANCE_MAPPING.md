# KERNELS Compliance Mapping

This document maps KERNELS architectural invariants and security properties to regulatory requirements for high-risk AI systems. Organizations deploying AI agents under regulatory oversight can use KERNELS to demonstrate compliance with record-keeping, human oversight, and auditability requirements.

---

## Executive Summary

KERNELS provides **technical enforcement** of governance controls that regulatory frameworks typically describe as organizational requirements. Rather than relying on policy documents and manual procedures, KERNELS makes governance **executable** through:

1. **Immutable audit trail** (hash-chained ledger)
2. **Cryptographic authorization** (permit tokens with HMAC signatures)
3. **Fail-closed enforcement** (deny-by-default, no implicit allow)
4. **Deterministic state machine** (predictable, verifiable transitions)

This document shows how these properties map to specific regulatory requirements.

---

## Table of Contents

1. [EU AI Act](#eu-ai-act)
2. [ISO 42001 AI Management System](#iso-42001)
3. [UK AI Safety Institute Guidance](#uk-aisi)
4. [NIST AI Risk Management Framework](#nist-ai-rmf)
5. [SOC 2 Type II Controls](#soc-2)
6. [Mapping Summary Table](#mapping-summary)

---

## EU AI Act

The EU AI Act (Regulation 2024/1689) establishes requirements for high-risk AI systems. KERNELS directly addresses several key articles.

### Article 12: Record-Keeping

**Requirement**:
> "Providers of high-risk AI systems shall keep logs automatically generated by the AI system to the extent such logs are under their control. The logs shall enable the identification of the AI system and record the period of each use of the system, the database against which input data has been checked, the input data for which the search has led to a match, and the identification of the natural persons involved."

**KERNELS Mapping**:

| EU AI Act Requirement | KERNELS Invariant | Implementation |
|-----------------------|-------------------|----------------|
| Automatically generated logs | **INV-AUDIT** | All state transitions logged to immutable ledger |
| Period of each use | **AuditEntry.ts_ms** | Monotonic timestamp for every entry |
| Input data for which search has led to a match | **AuditEntry.params_hash** | SHA-256 hash of all tool parameters |
| Identification of persons involved | **AuditEntry.actor** + **PermitToken.issuer/subject** | Actor identity + cryptographic attribution |
| Tamper-evident logs | **INV-HASH-CHAIN** | SHA-256 chain with prev_hash linkage |

**Evidence**:
- Export `EvidenceBundle` contains full ledger with hash chain
- Each entry includes: `ledger_seq`, `ts_ms`, `actor`, `decision`, `params_hash`, `permit_digest`
- Audit trail is **append-only** and **tamper-evident**

**Code Reference**: `kernels/audit/ledger.py`, `kernels/common/types.py::AuditEntry`

---

### Article 14: Human Oversight

**Requirement**:
> "High-risk AI systems shall be designed and developed in such a way as to enable effective oversight by natural persons during the period in which they are in use. Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights."

**KERNELS Mapping**:

| EU AI Act Requirement | KERNELS Invariant | Implementation |
|-----------------------|-------------------|----------------|
| Effective oversight by natural persons | **Permit Token System** | All dangerous actions require signed permits from human operators |
| Prevent risks before execution | **INV-FAIL-CLOSED** | Execution blocked unless permit is cryptographically verified |
| No automatic execution | **INV-NO-IMPLICIT-ALLOW** | No tool can execute without explicit authorization |
| Ability to interrupt | **HALTED state** | Kernel can be halted mid-execution with audit trail preserved |

**Evidence**:
- Permit tokens are **signed by human operators** using HMAC keys
- Permits specify: `issuer` (operator), `subject` (agent), `action` (tool), `max_executions`
- Replay protection prevents permit reuse: single-use permits enforce 1:1 human approval
- **MISSING_PERMIT** denial reason when authorization absent

**Code Reference**: `kernels/permits.py`, `spec/PERMIT_TOKENS.md`

---

### Article 16: Obligations of Providers

**Requirement**:
> "Providers of high-risk AI systems shall... ensure that logs automatically generated by their high-risk AI systems are kept for a period appropriate to the intended purpose of the AI system, of at least 6 months."

**KERNELS Mapping**:

| EU AI Act Requirement | KERNELS Invariant | Implementation |
|-----------------------|-------------------|----------------|
| Log retention | **EvidenceBundle** export | Ledger entries exportable as JSON for long-term storage |
| Appropriate period | **Configurable** | Organization controls evidence bundle archival |
| Integrity verification | **INV-HASH-CHAIN** | Root hash enables integrity verification at any point |

**Evidence**:
- `export_evidence()` returns `EvidenceBundle` with all entries + root hash
- Evidence bundles are **self-verifying**: hash chain allows independent validation
- Entries include `ledger_seq` for deterministic ordering across restarts

**Code Reference**: `kernels/variants/base.py::export_evidence()`

---

## ISO 42001 AI Management System

ISO/IEC 42001:2023 specifies requirements for establishing, implementing, maintaining, and continually improving an AI management system.

### Control A.5.1: Record Management

**Requirement**:
> "The organization shall create and retain records to provide evidence of conformity to requirements of the AI management system and of results achieved."

**KERNELS Mapping**:

| ISO 42001 Control | KERNELS Invariant | Implementation |
|-------------------|-------------------|----------------|
| Evidence of conformity | **INV-AUDIT** | Every decision (ALLOW/DENY/HALT) recorded in ledger |
| Results achieved | **AuditEntry.tool_result** | Tool execution results linked to audit entry |
| Deterministic records | **INV-DETERMINISM** + **ledger_seq** | Reproducible audit trail across restarts |

**Evidence**:
- Audit entries include: `decision`, `state_from`, `state_to`, `tool_name`, `params_hash`, `evidence_hash`
- Hash chain ensures **immutability**: tampering detectable via root hash verification

---

### Control A.6.2: Accountability for AI System Decisions

**Requirement**:
> "The organization shall establish and maintain accountability for AI system decisions and actions."

**KERNELS Mapping**:

| ISO 42001 Control | KERNELS Invariant | Implementation |
|-------------------|-------------------|----------------|
| Accountability for decisions | **Permit attribution** | `PermitToken.issuer` + `PermitToken.subject` link decision to actors |
| Traceability | **proposal_hash → permit_digest → audit entry** | Complete chain from proposal to execution |
| Non-repudiation | **HMAC signature** | Cryptographic proof of authorization (cannot be forged without key) |

**Evidence**:
- Permits bind: `proposal_hash` (what was requested) → `permit_id` (who authorized) → `audit entry` (what was executed)
- **DecisionEnvelope** binds verified permit to executed parameters (TOCTOU protection)
- Audit entry includes `permit_nonce` for cross-restart replay detection

---

## UK AI Safety Institute Guidance

The UK AI Safety Institute (AISI) provides principles for safe and responsible AI development. KERNELS addresses several core principles.

### Principle: Transparency and Explainability

**Guidance**:
> "AI systems should be transparent and explainable, enabling scrutiny and accountability."

**KERNELS Mapping**:

| AISI Principle | KERNELS Invariant | Implementation |
|----------------|-------------------|----------------|
| Transparent decision-making | **State machine visibility** | All transitions logged: BOOTING → IDLE → VALIDATING → ARBITRATING → EXECUTING → AUDITING |
| Explainable outcomes | **Audit trail + permit verification** | Every DENY includes `permit_denial_reasons` explaining why |
| Scrutiny-ready | **EvidenceBundle export** | Full audit trail exportable for external review |

**Evidence**:
- Audit entries show: `state_from`, `state_to`, `decision`, `permit_verification`
- Denial reasons include: `MISSING_PERMIT`, `REPLAY_DETECTED`, `SIGNATURE_INVALID`, `JURISDICTION_MISMATCH`, `PARAMS_MISMATCH`

---

### Principle: Robustness and Reliability

**Guidance**:
> "AI systems should be robust, secure, and safe by design."

**KERNELS Mapping**:

| AISI Principle | KERNELS Invariant | Implementation |
|----------------|-------------------|----------------|
| Fail-safe behavior | **INV-FAIL-CLOSED** | Deny-by-default; execution only on explicit ALLOW |
| Security by design | **Permit verification** | HMAC signatures prevent forgery; nonce registry prevents replay |
| Deterministic operation | **INV-DETERMINISM** | Same inputs + permits → same decisions (reproducible) |

**Evidence**:
- Fail-closed verification: 11-step permit verification pipeline
- Replay protection: cross-restart nonce persistence via ledger
- Deterministic ordering: `ledger_seq` ensures consistent reconstruction

---

## NIST AI Risk Management Framework

The NIST AI RMF provides a framework for managing risks associated with AI systems. KERNELS supports several key functions.

### GOVERN Function

**NIST RMF**: "Establishes roles, responsibilities, and processes for managing AI risks."

**KERNELS Mapping**:

| NIST Function | KERNELS Capability | Implementation |
|---------------|-------------------|----------------|
| Role-based access control | **Permit issuer/subject** | Permits specify who authorized (`issuer`) and who executes (`subject`) |
| Policy enforcement | **Jurisdiction policies** | Tool allowlists, parameter constraints enforced pre-execution |
| Audit and review | **Hash-chained ledger** | Immutable record of all decisions for post-hoc review |

---

### MAP Function

**NIST RMF**: "Establishes context to frame risks related to AI systems."

**KERNELS Mapping**:

| NIST Function | KERNELS Capability | Implementation |
|---------------|-------------------|----------------|
| Risk classification | **Variant kernels** | Strict, Permissive, Evidence-First variants for different risk levels |
| Context documentation | **Evidence linkage** | `evidence_hash` and `proposal_hash` link decisions to justifications |

---

### MEASURE Function

**NIST RMF**: "Employs metrics to track and measure AI risks."

**KERNELS Mapping**:

| NIST Function | KERNELS Capability | Implementation |
|---------------|-------------------|----------------|
| Quantifiable metrics | **Audit statistics** | Count of ALLOW/DENY/HALT decisions, permit usage, replay attempts |
| Continuous monitoring | **Real-time audit trail** | Every transition logged immediately (no batching) |

**Example Metrics from Audit Trail**:
- Total executions vs total denials (authorization rate)
- Replay attempts detected (security posture)
- Average time between permit issuance and use (operational latency)

---

## SOC 2 Type II Controls

SOC 2 audits evaluate controls for security, availability, confidentiality, and processing integrity. KERNELS supports several control objectives.

### CC6.1: Logical and Physical Access Controls

**SOC 2 Requirement**: "The entity implements logical access security measures to protect against threats from sources outside its system boundaries."

**KERNELS Mapping**:

| SOC 2 Control | KERNELS Invariant | Implementation |
|---------------|-------------------|----------------|
| Authentication | **Permit signatures** | HMAC-based cryptographic authentication of authorization |
| Authorization | **Permit verification** | Tool execution gated on verified permit |
| Audit logging | **INV-AUDIT** | All access attempts (ALLOW/DENY) logged to immutable ledger |

---

### CC7.2: System Monitoring

**SOC 2 Requirement**: "The entity monitors system components and the operation of those components for anomalies that are indicative of malicious acts, natural disasters, and errors."

**KERNELS Mapping**:

| SOC 2 Control | KERNELS Invariant | Implementation |
|---------------|-------------------|----------------|
| Anomaly detection | **Replay detection** | Nonce registry identifies replay attempts as anomalies |
| Continuous monitoring | **Real-time audit** | Every decision logged in real-time (not batch processed) |
| Alerting | **HALT state** | Kernel can halt on policy violations with audit preserved |

---

### PI1.4: Data Processing Integrity

**SOC 2 Requirement**: "The entity implements policies and procedures to make available or deliver output completely, accurately, and timely."

**KERNELS Mapping**:

| SOC 2 Control | KERNELS Invariant | Implementation |
|---------------|-------------------|----------------|
| Completeness | **Hash chain** | All entries linked; missing entries detectable via hash verification |
| Accuracy | **INV-DETERMINISM** | Deterministic execution; same inputs → same outputs |
| Integrity | **Tamper evidence** | Root hash verification proves ledger integrity |

---

## Mapping Summary

### KERNELS Invariants → Compliance Requirements

| KERNELS Invariant | EU AI Act | ISO 42001 | UK AISI | NIST AI RMF | SOC 2 |
|-------------------|-----------|-----------|---------|-------------|-------|
| INV-AUDIT | Art. 12 ✓ | A.5.1 ✓ | Transparency ✓ | MEASURE ✓ | CC7.2 ✓ |
| INV-HASH-CHAIN | Art. 12 ✓ | A.5.1 ✓ | Robustness ✓ | MEASURE ✓ | PI1.4 ✓ |
| INV-FAIL-CLOSED | Art. 14 ✓ | - | Robustness ✓ | GOVERN ✓ | CC6.1 ✓ |
| INV-NO-IMPLICIT-ALLOW | Art. 14 ✓ | - | Robustness ✓ | GOVERN ✓ | CC6.1 ✓ |
| INV-DETERMINISM | - | A.5.1 ✓ | Robustness ✓ | - | PI1.4 ✓ |
| Permit Tokens | Art. 14 ✓ | A.6.2 ✓ | - | GOVERN ✓ | CC6.1 ✓ |

---

## Evidence Package for Auditors

Organizations undergoing compliance audits can provide the following KERNELS-generated evidence:

### 1. Exported Evidence Bundle

**What**: `EvidenceBundle` JSON export from production kernel
**Contains**: Full audit ledger with hash chain, timestamps, actors, decisions, permit verification
**Verifiable**: Root hash can be independently recalculated to prove integrity
**Code**: `kernel.export_evidence()`

### 2. Permit Token Records

**What**: Issued permits with cryptographic signatures
**Contains**: Issuer, subject, action, parameters, constraints, validity period, nonce
**Verifiable**: HMAC signatures provable with shared key
**Code**: `PermitToken` instances exported to JSON

### 3. Nonce Registry Reconstruction

**What**: Proof that replay protection works across restarts
**Contains**: Ledger entries showing nonce usage, cross-restart reconstruction test results
**Verifiable**: Run `load_ledger()` on exported evidence to rebuild registry deterministically
**Code**: `BaseKernel.load_ledger(evidence)`

### 4. Invariant Validation Tests

**What**: Test suite proving invariants hold
**Contains**: 132 automated tests covering all invariants
**Verifiable**: Run `python -m unittest discover -s tests`
**Code**: `tests/test_*.py`

---

## Compliance Checklist

Use this checklist when preparing for regulatory review:

- [ ] **Audit Trail Integrity**
  - [ ] Export evidence bundle from production kernel
  - [ ] Verify root hash matches ledger entries
  - [ ] Confirm no gaps in `ledger_seq` numbering
  - [ ] Test `load_ledger()` reconstruction

- [ ] **Human Oversight**
  - [ ] Document permit issuance process
  - [ ] Show HMAC key management procedures
  - [ ] Demonstrate MISSING_PERMIT denials in audit trail
  - [ ] Prove single-use permits via replay tests

- [ ] **Traceability**
  - [ ] Map audit entries to issued permits
  - [ ] Link `proposal_hash` → `permit_digest` → `audit entry`
  - [ ] Show `actor` and `issuer` attribution for all executions

- [ ] **Fail-Closed Enforcement**
  - [ ] Demonstrate deny-by-default behavior
  - [ ] Show permit denials in test environment
  - [ ] Prove no execution without permit (integration tests)

- [ ] **Determinism and Reproducibility**
  - [ ] Run test suite (all 132 tests passing)
  - [ ] Demonstrate ledger reconstruction from evidence bundle
  - [ ] Show `ledger_seq` ordering prevents non-determinism

---

## Regulatory Benefits of KERNELS

| Without KERNELS | With KERNELS |
|-----------------|--------------|
| Manual audit logs (unstructured) | Structured, hash-chained audit trail |
| Policy documents (unenforced) | Cryptographically enforced authorization |
| Verbal approvals (no proof) | Signed permits with HMAC signatures |
| Hope-based security | Fail-closed enforcement |
| Retroactive compliance | Real-time governance |

---

## Additional Resources

- **Specification**: `spec/PERMIT_TOKENS.md` (normative permit token specification)
- **Architecture**: `docs/ARCHITECTURE.md` (system design and invariants)
- **Examples**: `examples/06_langchain_governed_agent.py` (governed agent demo)
- **Tests**: `tests/test_kernel_permit_integration.py` (integration test suite)

---

## Contact for Compliance Support

For organizations seeking compliance assistance or audit preparation:

- **Documentation**: https://github.com/anthropics/kernels
- **Issues**: https://github.com/anthropics/kernels/issues
- **Security**: security@anthropic.com (for responsible disclosure)

---

**Document Version**: 1.0
**Last Updated**: 2026-02-06
**Applies to KERNELS**: v0.2.0+
